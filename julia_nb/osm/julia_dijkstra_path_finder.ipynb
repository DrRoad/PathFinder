{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Pkg.add(\"LibExpat\"); using LibExpat\n",
    "Pkg.add(\"Winston\"); using Winston\n",
    "\n",
    "Pkg.add(\"MXNet\");\n",
    "ENV[\"MXNET_HOME\"] = \"/mxnet\"\n",
    "Pkg.add(\"GraphPlot\"); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "using MXNet\n",
    "using GraphPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LightGraphs\n",
    "import LightGraphs.SimpleGraphs: SimpleEdge, SimpleDiGraph\n",
    "include(\"CreateOSMGraphs.jl\")\n",
    "using CreateOSMGraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getOSMData\n",
      "197.946706 seconds (1.61 G allocations: 69.567 GiB, 52.45% gc time)\n",
      "intersections\n",
      "  0.059121 seconds (150.73 k allocations: 15.664 MiB)\n",
      "roadways\n",
      "  0.022804 seconds (21.82 k allocations: 2.127 MiB)\n",
      "segmentHighways\n",
      "  0.474165 seconds (2.02 M allocations: 49.316 MiB)\n",
      "createGraph\n",
      "  2.292778 seconds (23.57 M allocations: 907.592 MiB)\n",
      "202.217162 seconds (1.64 G allocations: 70.560 GiB, 51.35% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time graph, vprops, eprops, edgeDict, \n",
    "nodesLLA, highways, geohash2edgedict = CreateOSMGraphs.CreateOSMGraph(\"devilfork.osm\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{21772, 40283} directed simple Int64 graph"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphNodeId2MapNodeId = Dict()\n",
    "\n",
    "locs_x = Array{Float64, 1}(nv(graph))\n",
    "locs_y = Array{Float64, 1}(nv(graph))\n",
    "\n",
    "for (k, v) in sort(vprops, by=x -> vprops[x])\n",
    "    graphNodeId2MapNodeId[v] = k\n",
    "    println(nodesLLA[k].coords.lat, \",\", nodesLLA[k].coords.lon)\n",
    "    \n",
    "    locs_x[v] = nodesLLA[k].coords.lon\n",
    "    locs_y[v] = -nodesLLA[k].coords.lat\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_weights = Dict()\n",
    "\n",
    "for (edge, info_dict) in edgeDict\n",
    "    edge_weights[(edge.src, edge.dst)] = info_dict[:weight]\n",
    "end\n",
    "\n",
    "max_edge_weight = maximum(values(edge_weights))\n",
    "min_edge_weight = minimum(values(edge_weights))\n",
    "println(max_edge_weight)\n",
    "println(min_edge_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_nodes = nv(graph)\n",
    "max_out_degree = maximum(outdegree(graph))\n",
    "\n",
    "# generate distance matrix\n",
    "g_distmx = fill(Inf, (num_nodes, num_nodes))\n",
    "\n",
    "for (edge, info_dict) in edgeDict\n",
    "    # normalize weights\n",
    "    g_distmx[edge.src, edge.dst] = (info_dict[:weight] - min_edge_weight) / (max_edge_weight - min_edge_weight)\n",
    "end\n",
    "\n",
    "# calculate between centrality\n",
    "node_centrality = betweenness_centrality(graph)\n",
    "\n",
    "# normalize x y coordinates\n",
    "x_min, x_max = minimum(locs_x), maximum(locs_x)\n",
    "norm_locs_x = map(c -> (c - x_min) / (x_max - x_min), locs_x)\n",
    "\n",
    "y_min, y_max = minimum(locs_y), maximum(locs_y)\n",
    "norm_locs_y = map(c -> (c - y_min) / (y_max - y_min), locs_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gplot(graph, norm_locs_x, norm_locs_y, arrowlengthfrac=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_cosine_dist(p1, p2) = dot(p1, p2) / (norm(p1) * norm(p2))\n",
    "\n",
    "calc_euclidean_dist(p1, p2) = norm(p1 - p2)\n",
    "\n",
    "function encode_edges(G, parent, node, src, dst)\n",
    "    \n",
    "    ret = fill(0.0, (max_out_degree, 7))\n",
    "    \n",
    "    x_u = norm_locs_x[node]\n",
    "    y_u = norm_locs_y[node]\n",
    "    x_dst = norm_locs_x[dst]\n",
    "    y_dst = norm_locs_y[dst]\n",
    "\n",
    "    for (idx, out_neighbor) in enumerate(outneighbors(G, node))\n",
    "        \n",
    "        out_neighbor == parent && continue\n",
    "        \n",
    "        x_v = norm_locs_x[out_neighbor]\n",
    "        y_v = norm_locs_y[out_neighbor]\n",
    "        \n",
    "        ret[idx, 1] = 0\n",
    "        ret[idx, 2] = g_distmx[node, out_neighbor]\n",
    "        ret[idx, 3] = calc_cosine_dist([x_v-x_u, y_v-y_u], [x_dst-x_u, y_dst-y_u])\n",
    "        ret[idx, 4] = calc_euclidean_dist([x_v, y_v], [x_dst, y_dst])\n",
    "        ret[idx, 5] = x_v\n",
    "        ret[idx, 6] = y_v\n",
    "        \n",
    "        ret[idx, end] = out_neighbor\n",
    "        \n",
    "    end\n",
    "    \n",
    "    return (ret, x_dst, y_dst)\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function generate_stochastic_dataset(G; sample_size_lower_bound=100, verbose_frequent=10)\n",
    "    \n",
    "    pair_path_dict = Dict()\n",
    "    sample_cnt = 0\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    while true\n",
    "        src = rand(1:num_nodes)\n",
    "        dst = rand(1:num_nodes)\n",
    "        \n",
    "        src == dst && continue\n",
    "        \n",
    "        for (src, dst) in [(src, dst), (dst, src)]\n",
    "    \n",
    "            path = a_star(graph, src, dst, g_distmx)\n",
    "            \n",
    "            length(path) == 0 && break\n",
    "            \n",
    "            pair_path_dict[(src, dst)] = path\n",
    "            \n",
    "            parent_node = 0\n",
    "            cur_node = src\n",
    "            \n",
    "            for edge in path\n",
    "                \n",
    "#                 println(\"parent:($(parent_node)), X:($(cur_node), $(dst)), y:($(edge.dst))\")\n",
    "                \n",
    "                \n",
    "                push!(X, encode_edges(G, parent_node, cur_node, src, dst))\n",
    "                push!(y, edge.dst)\n",
    "                \n",
    "                parent_node = cur_node\n",
    "                cur_node = edge.dst\n",
    "                \n",
    "                sample_cnt += 1\n",
    "                sample_cnt % verbose_frequent == 0 && println(\"Collected $(sample_cnt) samples.\")\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        sample_cnt >= sample_size_lower_bound && break\n",
    "        \n",
    "    end\n",
    "    \n",
    "    return X, y, pair_path_dict, sample_cnt\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features, labels, pair_path_dict, sample_cnt = generate_stochastic_dataset(graph, sample_size_lower_bound=200000, verbose_frequent=1000);\n",
    "\n",
    "@assert length(features) == length(labels) == sample_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_path_len = maximum(map(e -> length(e), values(pair_path_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function find_label_idx(feature, label)\n",
    "    \n",
    "    num_row = size(feature)[1]\n",
    "    ret_idx = 1\n",
    "    \n",
    "    for row_idx in 1:num_row\n",
    "        if feature[row_idx, end] == label\n",
    "            ret_idx = row_idx\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    ret_idx\n",
    "end\n",
    "\n",
    "function augment_dataset(X, y; aug_multiple=20, verbose_frequent=500)\n",
    "    \n",
    "    org_sample_size = length(y)\n",
    "    aug_sample_size = aug_multiple * org_sample_size\n",
    "    feature_size = max_out_degree * 6 + 2\n",
    "    \n",
    "    X_aug, y_aug = zeros(Float32, aug_sample_size, feature_size), zeros(Int, aug_sample_size)\n",
    "    indices = 1:max_out_degree\n",
    "    \n",
    "    cur_sample_idx = 1\n",
    "    \n",
    "    for pair in zip(X, y)\n",
    "        feature = pair[1]\n",
    "        label = pair[2]\n",
    "        \n",
    "        for _ in 1:aug_multiple\n",
    "             \n",
    "            shuffled_indices = shuffle(MersenneTwister(now().instant.periods.value), indices)\n",
    "            \n",
    "            feature_tmp = feature[1][shuffled_indices, :]\n",
    "            label_tmp = find_label_idx(feature_tmp, label)\n",
    "            \n",
    "            feature_tmp = transpose(feature_tmp[:, 1:end-1])\n",
    "\n",
    "            \n",
    "            X_aug[cur_sample_idx, :] = push!(vcat(feature_tmp...), feature[2], feature[3])\n",
    "            y_aug[cur_sample_idx] = label_tmp - 1\n",
    "            \n",
    "            cur_sample_idx += 1\n",
    "            \n",
    "            if cur_sample_idx % verbose_frequent == 0\n",
    "                println(\"Processed $(cur_sample_idx) samples\")\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return transpose(X_aug), y_aug\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X, y = augment_dataset(features, labels, aug_multiple=20, verbose_frequent=500000)\n",
    "\n",
    "println(size(X))\n",
    "println(size(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_at = [rand() > 0.15 for i in 1:length(y)]\n",
    "\n",
    "X_train = X[:, split_at]\n",
    "y_train = y[split_at]\n",
    "\n",
    "X_val = X[:, .!split_at]\n",
    "y_val = y[.!split_at];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function build_model(context)\n",
    "\n",
    "    mlp = @mx.chain mx.Variable(:data)             =>\n",
    "      mx.FullyConnected(name=:fc1, num_hidden=1024) =>\n",
    "      mx.Activation(name=:relu1, act_type=:relu)   =>\n",
    "      mx.FullyConnected(name=:fc2, num_hidden=512)  =>\n",
    "      mx.Activation(name=:relu2, act_type=:relu)   =>\n",
    "      mx.FullyConnected(name=:fc3, num_hidden=max_out_degree)  =>\n",
    "      mx.SoftmaxOutput(name=:softmax)\n",
    "    \n",
    "    return mx.FeedForward(mlp, context=context)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_provider = mx.ArrayDataProvider(X_train, y_train, batch_size=batch_size, shuffle=true)\n",
    "val_provider = mx.ArrayDataProvider(X_val, y_val, batch_size=batch_size);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(mx.gpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mx.fit(model, mx.ADAM(),\n",
    "    train_provider,\n",
    "    n_epoch=1,\n",
    "    eval_data=val_provider,\n",
    "    verbosity=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function nn_infer_next_node(G, parent, cur_node, src, dst, model)\n",
    "\n",
    "    input_vec, x_dst, y_dst = encode_edges(G, parent, cur_node, src, dst)\n",
    "    real_input_vec = push!(vcat(transpose(input_vec[:, 1:end-1])...), x_dst, y_dst)\n",
    "    \n",
    "    pred = mx.predict(model, mx.ArrayDataProvider(reshape(real_input_vec, :, 1)), verbosity=0)\n",
    "    pred_idx = findmax(pred)[2]\n",
    "    neighbor = Int(input_vec[pred_idx, end])\n",
    "    \n",
    "    if neighbor == 0\n",
    "        \n",
    "        avaliable_neighbors = filter(x -> x > 0, input_vec[:, end])\n",
    "        \n",
    "        if length(avaliable_neighbors) != 0\n",
    "            println(\"Invalid prediction, randomizing next node\")\n",
    "            neighbor = Int(avaliable_neighbors[rand(1:end)])\n",
    "        else\n",
    "            # TODO the algorithm can be made smarter\n",
    "            return -1, 0\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return neighbor, edge_weights[(cur_node, neighbor)]\n",
    "end\n",
    "\n",
    "function dijkstra_path_finder(G, src, dst, model; invalid_path_len_threshold=100)\n",
    "    \n",
    "    path = [src]\n",
    "    parent_node = 0\n",
    "    cur_node = src\n",
    "    total_weights = 0.0\n",
    "    \n",
    "    while true\n",
    "        if length(path) >= invalid_path_len_threshold\n",
    "            return path, total_weights, false\n",
    "        end\n",
    "        \n",
    "        next_node, weight = nn_infer_next_node(G, parent_node, cur_node, src, dst, model)\n",
    "        \n",
    "        if next_node == -1\n",
    "            \n",
    "            if !has_edge(G, (cur_node, parent_node))\n",
    "                return path, total_weights, false\n",
    "            end\n",
    "            \n",
    "            println(\"No available node to choose, turning back\")\n",
    "            parent_node, cur_node = cur_node, parent_node\n",
    "            continue\n",
    "        end\n",
    "        \n",
    "        total_weights += weight\n",
    "        push!(path, next_node)\n",
    "        \n",
    "        if next_node == dst\n",
    "            return path, total_weights, true\n",
    "        end\n",
    "        \n",
    "        parent_node = cur_node\n",
    "        cur_node = next_node\n",
    "    end\n",
    "\n",
    "end\n",
    "\n",
    "function build_ground_truth_path(src, dst)\n",
    "    \n",
    "    edges = pair_path_dict[(src, dst)]\n",
    "    \n",
    "    path = [edges[1].src]\n",
    "    \n",
    "    for edge in edges\n",
    "       push!(path, edge.dst) \n",
    "    end\n",
    "    \n",
    "    path\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function calc_statistics(G, num_to_test)\n",
    "   \n",
    "    found_cnt = 0\n",
    "    opt_path_cnt = 0\n",
    "    \n",
    "    pairs = shuffle(collect(keys(pair_path_dict)))[1:num_to_test]\n",
    "    \n",
    "    for pair in pairs\n",
    "        src, dst = pair[1], pair[2]\n",
    "\n",
    "        nn_path, _, found = dijkstra_path_finder(G, src, dst, model)\n",
    "        dijkstra_path = build_ground_truth_path(src, dst)\n",
    "        \n",
    "        found == false && continue\n",
    "        \n",
    "        found_cnt += 1\n",
    "        \n",
    "        if nn_path == dijkstra_path\n",
    "            opt_path_cnt += 1\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return found_cnt, opt_path_cnt\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function print_paths_statistics(G, num_to_test)\n",
    "\n",
    "    num_total_path = num_to_test\n",
    "\n",
    "    found_cnt, opt_path_cnt = calc_statistics(G, num_to_test)\n",
    "    \n",
    "    @printf \"%d out of %d can find path: %f\\n\" found_cnt num_total_path float(found_cnt)/num_total_path\n",
    "    @printf \"%d out of %d can find optimal path: %f\\n\" opt_path_cnt found_cnt float(opt_path_cnt)/found_cnt\n",
    "    @printf \"%d out of %d all paths can find optimal paths: %f\\n\" opt_path_cnt num_total_path float(opt_path_cnt)/num_total_path\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_paths_statistics(graph, 500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
