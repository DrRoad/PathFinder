{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Pkg.add(\"LibExpat\"); using LibExpat\n",
    "Pkg.add(\"Winston\"); using Winston\n",
    "\n",
    "Pkg.clone(\"MXNet\");\n",
    "ENV[\"MXNET_HOME\"] = \"/mxnet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using MXNet\n",
    "using GraphPlot\n",
    "using PyPlot\n",
    "using PyCall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: deprecated syntax \"typealias Styles @compat Union{Style,Dict{Int,Style}}\" at /home/hitmann/hitmann/PathFinder/julia_nb/osm/plot.jl:8.\n",
      "Use \"const Styles = @compat Union{Style,Dict{Int,Style}}\" instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "generate_weights_with_factors (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using LightGraphs\n",
    "import LightGraphs.SimpleGraphs: SimpleEdge, SimpleDiGraph\n",
    "include(\"CreateOSMGraphs.jl\")\n",
    "using CreateOSMGraphs;\n",
    "include(\"utils.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the map data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getOSMData\n",
      "  1.200896 seconds (8.83 M allocations: 400.206 MiB, 10.39% gc time)\n",
      "intersections\n",
      "  0.000262 seconds (1.51 k allocations: 186.500 KiB)\n",
      "roadways\n",
      "  0.009992 seconds (1.98 k allocations: 129.438 KiB)\n",
      "segmentHighways\n",
      "  0.243343 seconds (93.09 k allocations: 4.697 MiB, 2.53% gc time)\n",
      "createGraph\n",
      "  0.162631 seconds (137.25 k allocations: 5.752 MiB)\n",
      "  3.154811 seconds (9.86 M allocations: 453.647 MiB, 4.77% gc time)\n"
     ]
    }
   ],
   "source": [
    "osm_fn = \"kista.osm\"\n",
    "@time graph, vprops, eprops, edgeDict, \n",
    "nodesLLA, highways, geohash2edgedict = CreateOSMGraphs.CreateOSMGraph(osm_fn);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the dictionary from graph node id to map node id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphNodeId2MapNodeId = Dict()\n",
    "\n",
    "locs_x = Array{Float64, 1}(nv(graph))\n",
    "locs_y = Array{Float64, 1}(nv(graph))\n",
    "\n",
    "for (k, v) in sort(vprops, by=x->vprops[x])\n",
    "    graphNodeId2MapNodeId[v] = k\n",
    "#     println(nodesLLA[k].coords.lat, \",\", nodesLLA[k].coords.lon);\n",
    "    \n",
    "    locs_x[v] = nodesLLA[k].coords.lon\n",
    "    locs_y[v] = nodesLLA[k].coords.lat\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.9832329\n",
      "17.9324095\n",
      "59.4164298\n",
      "59.3940158\n"
     ]
    }
   ],
   "source": [
    "println(maximum(locs_x))\n",
    "println(minimum(locs_x))\n",
    "println(maximum(locs_y))\n",
    "println(minimum(locs_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate important features of each graph edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.97893868130066\n",
      "0.002803081050596522\n"
     ]
    }
   ],
   "source": [
    "edge_weights = Dict()\n",
    "\n",
    "for (edge, info_dict) in edgeDict\n",
    "    \n",
    "    # sunny/rainy/snowy     \n",
    "    info_dict[:weather] = 0\n",
    "    \n",
    "    num_vehicles = Int(ceil(randexp()) * 10)\n",
    "    info_dict[:num_vehicles] = num_vehicles\n",
    "    \n",
    "    # Randomize centrality within (0, 1)\n",
    "    info_dict[:centrality] = rand()\n",
    "    \n",
    "    # Add rush hour information\n",
    "    info_dict[:rush_hour] = false\n",
    "    \n",
    "    # Add highway information\n",
    "    info_dict[:is_highway] = haskey(highways, info_dict[:id])\n",
    "    \n",
    "    # Which day of the week\n",
    "    info_dict[:day_of_week] = 0\n",
    "    \n",
    "    # Is holiday?\n",
    "    info_dict[:is_holiday] = false\n",
    "    \n",
    "    edge_weight = generate_weights_with_factors(info_dict)\n",
    "    \n",
    "    info_dict[:weight] = edge_weight\n",
    "    edge_weights[(edge.src, edge.dst)] = edge_weight\n",
    "end\n",
    "\n",
    "max_edge_weight = maximum(values(edge_weights))\n",
    "min_edge_weight = minimum(values(edge_weights))\n",
    "println(max_edge_weight)\n",
    "println(min_edge_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_nodes = nv(graph)\n",
    "max_out_degree = maximum(outdegree(graph))\n",
    "\n",
    "# generate distance matrix\n",
    "g_distmx = fill(Inf, (num_nodes, num_nodes))\n",
    "\n",
    "for (edge, info_dict) in edgeDict\n",
    "    # normalize weights\n",
    "    g_distmx[edge.src, edge.dst] = (info_dict[:weight] - min_edge_weight) / (max_edge_weight - min_edge_weight)\n",
    "end\n",
    "\n",
    "# calculate between centrality\n",
    "node_centrality = betweenness_centrality(graph)\n",
    "\n",
    "# normalize x y coordinates\n",
    "x_min, x_max = minimum(locs_x), maximum(locs_x)\n",
    "norm_locs_x = map(c -> (c - x_min) / (x_max - x_min), locs_x)\n",
    "\n",
    "y_min, y_max = minimum(locs_y), maximum(locs_y)\n",
    "norm_locs_y = map(c -> (c - y_min) / (y_max - y_min), locs_y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A plot of northern Stockholm road network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gplot(graph, locs_x, -locs_y, arrowlengthfrac=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_cosine_dist(p1, p2) = dot(p1, p2) / (norm(p1) * norm(p2))\n",
    "\n",
    "calc_euclidean_dist(p1, p2) = norm(p1 - p2)\n",
    "\n",
    "function encode_edges(G, parent, node, src, dst)\n",
    "    \n",
    "    ret = fill(0.0, (max_out_degree, 7))\n",
    "    \n",
    "    x_u = norm_locs_x[node]\n",
    "    y_u = norm_locs_y[node]\n",
    "    x_dst = norm_locs_x[dst]\n",
    "    y_dst = norm_locs_y[dst]\n",
    "\n",
    "    for (idx, out_neighbor) in enumerate(outneighbors(G, node))\n",
    "        \n",
    "        out_neighbor == parent && continue\n",
    "        \n",
    "        x_v = norm_locs_x[out_neighbor]\n",
    "        y_v = norm_locs_y[out_neighbor]\n",
    "        \n",
    "        ret[idx, 1] = 0.0\n",
    "        ret[idx, 2] = g_distmx[node, out_neighbor]\n",
    "        ret[idx, 3] = calc_cosine_dist([x_v-x_u, y_v-y_u], [x_dst-x_u, y_dst-y_u])\n",
    "        ret[idx, 4] = calc_euclidean_dist([x_v, y_v], [x_dst, y_dst])\n",
    "        ret[idx, 5] = x_v\n",
    "        ret[idx, 6] = y_v\n",
    "        \n",
    "        ret[idx, end] = out_neighbor\n",
    "        \n",
    "    end\n",
    "    \n",
    "    return (ret, x_dst, y_dst)\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function generate_stochastic_dataset(G; sample_size_lower_bound=100, verbose_frequent=10)\n",
    "    \n",
    "    pair_path_dict = Dict()\n",
    "    sample_cnt = 0\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    while true\n",
    "        src = rand(1:num_nodes)\n",
    "        dst = rand(1:num_nodes)\n",
    "        \n",
    "        src == dst && continue\n",
    "        \n",
    "        (src, dst) in keys(edge_weights) && continue    \n",
    "        \n",
    "        for (src, dst) in [(src, dst), (dst, src)]\n",
    "    \n",
    "            path = a_star(graph, src, dst, g_distmx)\n",
    "            \n",
    "            length(path) == 0 && break\n",
    "            \n",
    "            pair_path_dict[(src, dst)] = path\n",
    "            \n",
    "            parent_node = 0\n",
    "            cur_node = src\n",
    "            \n",
    "            for edge in path\n",
    "                \n",
    "#                 println(\"parent:($(parent_node)), X:($(cur_node), $(dst)), y:($(edge.dst))\")\n",
    "                \n",
    "                \n",
    "                push!(X, encode_edges(G, parent_node, cur_node, src, dst))\n",
    "                push!(y, edge.dst)\n",
    "                \n",
    "                parent_node = cur_node\n",
    "                cur_node = edge.dst\n",
    "                \n",
    "                sample_cnt += 1\n",
    "                sample_cnt % verbose_frequent == 0 && println(\"Collected $(sample_cnt) samples.\")\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        sample_cnt >= sample_size_lower_bound && break\n",
    "        \n",
    "    end\n",
    "    \n",
    "    return X, y, pair_path_dict, sample_cnt\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@time begin\n",
    "features, labels, pair_path_dict, sample_cnt = generate_stochastic_dataset(graph, sample_size_lower_bound=10000, verbose_frequent=2000);\n",
    "end\n",
    "@assert length(features) == length(labels) == sample_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pair_path_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_path_len = maximum(map(e -> length(e), values(pair_path_dict)))\n",
    "println(max_path_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is data augmentation really helpful?\n",
    "Perhap when overdone, data augmentation only makes it harder to train.\n",
    "As of this moment, data augmentation will be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function find_label_idx(feature, label)\n",
    "    \n",
    "    num_row = size(feature)[1]\n",
    "    ret_idx = 1\n",
    "    \n",
    "    for row_idx in 1:num_row\n",
    "        if feature[row_idx, end] == label\n",
    "            ret_idx = row_idx\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    ret_idx\n",
    "end\n",
    "\n",
    "function augment_dataset(X, y; aug_multiple=20, verbose_frequent=500)\n",
    "    \n",
    "    org_sample_size = length(y)\n",
    "    aug_sample_size = aug_multiple * org_sample_size\n",
    "    feature_size = max_out_degree * 6 + 2\n",
    "    \n",
    "    X_aug, y_aug = zeros(Float32, aug_sample_size, feature_size), zeros(Int, aug_sample_size)\n",
    "    indices = 1:max_out_degree\n",
    "    \n",
    "    cur_sample_idx = 1\n",
    "    \n",
    "    for pair in zip(X, y)\n",
    "        feature = pair[1]\n",
    "        label = pair[2]\n",
    "        \n",
    "        for _ in 1:aug_multiple\n",
    "             \n",
    "#             shuffled_indices = shuffle(MersenneTwister(now().instant.periods.value), indices)\n",
    "            shuffled_indices = indices\n",
    "            feature_tmp = feature[1][shuffled_indices, :]\n",
    "            label_tmp = find_label_idx(feature_tmp, label)\n",
    "            \n",
    "            feature_tmp = transpose(feature_tmp[:, 1:end-1])\n",
    "\n",
    "            \n",
    "            X_aug[cur_sample_idx, :] = push!(vcat(feature_tmp...), feature[2], feature[3])\n",
    "            y_aug[cur_sample_idx] = label_tmp - 1\n",
    "            \n",
    "            cur_sample_idx += 1\n",
    "            \n",
    "            if cur_sample_idx % verbose_frequent == 0\n",
    "                println(\"Processed $(cur_sample_idx) samples\")\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return transpose(X_aug), y_aug\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X, y = augment_dataset(features, labels, aug_multiple=1, verbose_frequent=5000)\n",
    "\n",
    "println(size(X))\n",
    "println(size(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count(x -> x == 0, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_at = [rand() > 0.2 for i in 1:length(y)]\n",
    "\n",
    "X_train = X[:, split_at]\n",
    "y_train = y[split_at]\n",
    "\n",
    "X_val = X[:, .!split_at]\n",
    "y_val = y[.!split_at];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(size(X_train))\n",
    "println(size(y_train))\n",
    "println(size(X_val))\n",
    "println(size(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function build_model(context)\n",
    "\n",
    "    mlp = @mx.chain mx.Variable(:data)             =>\n",
    "      mx.FullyConnected(name=:fc1, num_hidden=1024) =>\n",
    "      mx.Activation(name=:relu1, act_type=:relu)   =>\n",
    "      mx.FullyConnected(name=:fc2, num_hidden=512)  =>\n",
    "      mx.Activation(name=:relu2, act_type=:relu)   =>\n",
    "      mx.FullyConnected(name=:fc3, num_hidden=max_out_degree)  =>\n",
    "      mx.SoftmaxOutput(name=:softmax)\n",
    "    \n",
    "    return mx.FeedForward(mlp, context=context)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First overfit the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_provider = mx.ArrayDataProvider(X, y, batch_size=batch_size, shuffle=true)\n",
    "val_provider = mx.ArrayDataProvider(X, y, batch_size=batch_size);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(mx.gpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mx.fit(model, mx.ADAM(),\n",
    "    train_provider,\n",
    "    n_epoch=150,\n",
    "    eval_data=val_provider,\n",
    "    verbosity=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using MLBase\n",
    "\n",
    "pred = mx.predict(model, \n",
    "        mx.ArrayDataProvider(X, batch_size=batch_size), verbosity=0)\n",
    "\n",
    "pred = map(i -> indmax(pred[:, i]), 1:length(y))\n",
    "\n",
    "confusmat(max_out_degree, y+1, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function nn_infer_next_node(G, parent, cur_node, src, dst, model)\n",
    "\n",
    "    input_vec, x_dst, y_dst = encode_edges(G, parent, cur_node, src, dst)\n",
    "    real_input_vec = push!(vcat(transpose(input_vec[:, 1:end-1])...), x_dst, y_dst)\n",
    "    \n",
    "    pred = mx.predict(model, mx.ArrayDataProvider(reshape(real_input_vec, :, 1)), verbosity=0)\n",
    "    pred_idx = findmax(pred)[2]\n",
    "    neighbor = Int(input_vec[pred_idx, end])\n",
    "    \n",
    "    if neighbor == 0\n",
    "        \n",
    "        avaliable_neighbors = filter(x -> x > 0, input_vec[:, end])\n",
    "        \n",
    "        if length(avaliable_neighbors) != 0\n",
    "            println(\"Invalid prediction, randomizing next node\")\n",
    "            neighbor = Int(avaliable_neighbors[rand(1:end)])\n",
    "        else\n",
    "            # TODO the algorithm can be made smarter\n",
    "            return -1, 0\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return neighbor, edge_weights[(cur_node, neighbor)]\n",
    "end\n",
    "\n",
    "function dijkstra_path_finder(G, src, dst, model; invalid_path_len_threshold=200)\n",
    "    \n",
    "    path = [src]\n",
    "    parent_node = 0\n",
    "    cur_node = src\n",
    "    total_weights = 0.0\n",
    "    \n",
    "    while true\n",
    "        if length(path) >= invalid_path_len_threshold\n",
    "            return path, total_weights, false\n",
    "        end\n",
    "        \n",
    "        next_node, weight = nn_infer_next_node(G, parent_node, cur_node, src, dst, model)\n",
    "        \n",
    "        if next_node == -1\n",
    "            \n",
    "            if !has_edge(G, (cur_node, parent_node))\n",
    "                return path, total_weights, false\n",
    "            end\n",
    "            \n",
    "            println(\"No available node to choose, turning back\")\n",
    "            parent_node, cur_node = cur_node, parent_node\n",
    "            continue\n",
    "        end\n",
    "        \n",
    "        total_weights += weight\n",
    "        push!(path, next_node)\n",
    "        \n",
    "        if next_node == dst\n",
    "            return path, total_weights, true\n",
    "        end\n",
    "        \n",
    "        parent_node = cur_node\n",
    "        cur_node = next_node\n",
    "    end\n",
    "\n",
    "end\n",
    "\n",
    "function build_ground_truth_path(src, dst)\n",
    "    \n",
    "    edges = pair_path_dict[(src, dst)]\n",
    "    \n",
    "    path = [edges[1].src]\n",
    "    \n",
    "    for edge in edges\n",
    "       push!(path, edge.dst) \n",
    "    end\n",
    "    \n",
    "    path\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function calc_statistics(G, num_to_test)\n",
    "   \n",
    "    found_cnt = 0\n",
    "    opt_path_cnt = 0\n",
    "    \n",
    "    pairs = shuffle(collect(keys(pair_path_dict)))[1:num_to_test]\n",
    "    \n",
    "    for pair in pairs\n",
    "        src, dst = pair[1], pair[2]\n",
    "\n",
    "        nn_path, _, found = dijkstra_path_finder(G, src, dst, model, \n",
    "                                invalid_path_len_threshold=max_path_len * 2)\n",
    "        dijkstra_path = build_ground_truth_path(src, dst)\n",
    "        \n",
    "        found == false && continue\n",
    "        \n",
    "        found_cnt += 1\n",
    "        \n",
    "        if nn_path == dijkstra_path\n",
    "            opt_path_cnt += 1\n",
    "        else\n",
    "            println(nn_path)\n",
    "            println(dijkstra_path)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return found_cnt, opt_path_cnt\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function print_paths_statistics(G, num_to_test)\n",
    "\n",
    "    num_total_path = num_to_test\n",
    "\n",
    "    found_cnt, opt_path_cnt = calc_statistics(G, num_to_test)\n",
    "    \n",
    "    @printf \"%d out of %d can find path: %f\\n\" found_cnt num_total_path float(found_cnt)/num_total_path\n",
    "    @printf \"%d out of %d can find optimal path: %f\\n\" opt_path_cnt found_cnt float(opt_path_cnt)/found_cnt\n",
    "    @printf \"%d out of %d all paths can find optimal paths: %f\\n\" opt_path_cnt num_total_path float(opt_path_cnt)/num_total_path\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_paths_statistics(graph, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N.B.\n",
    "\n",
    "When the model is able to find the optimal path\n",
    "with high probability, the model has learned well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "percentage_found = []\n",
    "percentage_opt_found = []\n",
    "percentage_opt_all = []\n",
    "\n",
    "for _ in 1:10\n",
    "    num_total_path = 200\n",
    "    \n",
    "    found_cnt, opt_path_cnt = calc_statistics(graph, num_total_path)\n",
    "    push!(percentage_found, found_cnt/num_total_path)\n",
    "    push!(percentage_opt_found, opt_path_cnt/found_cnt)\n",
    "    push!(percentage_opt_all, opt_path_cnt/num_total_path)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot([percentage_found, percentage_opt_found, percentage_opt_all],\n",
    "        labels=[\"found/all\", \"opt/found\", \"opt/all\"]) # Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pyimport networkx as nx\n",
    "\n",
    "distmx = fill(Inf, (nv(graph), nv(graph)))\n",
    "\n",
    "function build_networkx_graph(julia_graph)\n",
    "    \n",
    "    \n",
    "    \n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    for (edge, _) in edgeDict\n",
    "#         print(node, coord[0], coord[1])\n",
    "        weight = (0.5 * rand() + 0.5) * \n",
    "                        calc_euclidean_dist([norm_locs_x[edge.src], norm_locs_y[edge.src]], \n",
    "                                            [norm_locs_x[edge.dst], norm_locs_y[edge.dst]])\n",
    "        nx.add_path(G, [edge.src, edge.dst], weight=weight)\n",
    "        distmx[edge.src, edge.dst] = weight\n",
    "    end\n",
    "    \n",
    "    G\n",
    "end\n",
    "\n",
    "function build_ground_truth_path(path_edges)\n",
    "    \n",
    "    path = [path_edges[1].src]\n",
    "    edges = []\n",
    "    \n",
    "    for edge in path_edges\n",
    "        push!(path, edge.dst)\n",
    "        push!(edges, (edge.src, edge.dst))\n",
    "    end\n",
    "    \n",
    "    return path, edges\n",
    "end\n",
    "\n",
    "function plot_gt_nn_comparison(graph, gt_path_nodes, nn_path_nodes)\n",
    "    \n",
    "    G = build_networkx_graph(graph)\n",
    "    \n",
    "    pos = Dict()\n",
    "\n",
    "    for node in 1:nv(graph)\n",
    "        pos[node] = (locs_x[node], locs_y[node])\n",
    "    end\n",
    "\n",
    "    node_color = [\"c\" for _ in 1:nv(graph)];\n",
    "    node_size = [0.01 for _ in 1:nv(graph)];\n",
    "    \n",
    "    # Mark ground truth path\n",
    "    node_color[gt_path_nodes[end]] = \"g\"\n",
    "    node_color[gt_path_nodes[1]] = \"k\"\n",
    "\n",
    "    node_size[gt_path_nodes[1]] = 20\n",
    "    node_size[gt_path_nodes[end]] = 20\n",
    "\n",
    "    for node in gt_path_nodes[2:end-1]\n",
    "        node_color[node] = \"r\"\n",
    "        node_size[node] = 1\n",
    "    end\n",
    "\n",
    "    # Mark nn path\n",
    "    for node in nn_path_nodes[2:end-1]\n",
    "        node_color[node] = \"b\"\n",
    "        node_size[node] = 1\n",
    "    end\n",
    "    \n",
    "    nx.draw_networkx(G, pos=pos, \n",
    "                    with_labels=false,\n",
    "                    nodelist=1:nv(graph),\n",
    "                    node_size=node_size, \n",
    "                    width=0.01,\n",
    "                    arrows=false,\n",
    "                    node_color=node_color)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_path_nodes = [1417, 2228, 763, 3, 3475, 2886, 1173, 2173, 1271, 1274, 2121, 1238, 529, 897, 3266, 1439, 2639, 1719, 155, 169, 2699, 2096, 1292, 273, 13, 1502, 2216, 1101, 1640, 127, 1039, 3351, 2764, 1562, 1667, 2078, 665, 551, 2747, 2856, 2432, 2556, 3034, 1899, 561, 2583, 3176, 80, 2723, 2514, 1960, 1099, 838, 1771, 1249, 999, 1804, 2748, 2905, 3356, 1123, 1309]\n",
    "nn_path_nodes = [1417, 2228, 2855, 763, 3, 3475, 2886, 1173, 2181, 2932, 2262, 2720, 1050, 252, 3078, 1033, 1279, 2226, 2964, 434, 3131, 850, 2898, 369, 739, 1492, 1780, 1996, 2653, 2910, 251, 2524, 483, 545, 2832, 2486, 596, 3415, 127, 1039, 3351, 2764, 1562, 1667, 2078, 665, 551, 2747, 2856, 2432, 2556, 3034, 1899, 561, 2583, 3176, 80, 2723, 2514, 1960, 1099, 838, 1771, 1249, 999, 1804, 2748, 2905, 3356, 1123, 1309];\n",
    "\n",
    "plot_gt_nn_comparison(graph, gt_path_nodes, nn_path_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
