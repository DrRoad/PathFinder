{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some take-ways from this notebook\n",
    "\n",
    "Greedy strategy can be perfectly and easily approximated by a neural network;\n",
    "However, greedy strategy itself is sub-optimal compared to Dijkstra; the \n",
    "algorithm can easily be stuck in a cycle, leading to bad results.\n",
    "\n",
    "One thing that is a bit concerning is that the graph is small; the network\n",
    "tends to memorize the entire graph; some experiments on much bigger graphs\n",
    "should be conducted to verify that the network is actually learning something\n",
    "useful.\n",
    "\n",
    "It would be very interesting to see to what extent can Dijkstra be approximated.\n",
    "\n",
    "# Validate on new graphs\n",
    "\n",
    "A model that is trained on one random graph\n",
    "should and indeed can be used to infer paths\n",
    "on another random graph. This, to some extent,\n",
    "proves that the network has gained some knowledge,\n",
    "which is good news.\n",
    "In this case, the knowledge is the greedy strategy,\n",
    "i.e., always go with the edge that has the smallest\n",
    "weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "import logging\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_NODE = 100\n",
    "WEIGHT_MIN = .0\n",
    "WEIGHT_MAX = 1.\n",
    "OUT_DEGREE_MAX = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_low_degree_g(node_size=20, min_out_degree=2, max_out_degree=4, weight_min=WEIGHT_MIN, weight_max=WEIGHT_MAX):\n",
    "    \n",
    "    G = nx.DiGraph()\n",
    "    G.add_nodes_from(range(0, node_size))\n",
    "    \n",
    "    for node in G.nodes:\n",
    "        tmp_nodes = list(G.nodes)\n",
    "        tmp_nodes.remove(node)\n",
    "        random.shuffle(tmp_nodes)\n",
    "        \n",
    "        out_neighbors = tmp_nodes[:random.randint(min_out_degree, max_out_degree)]\n",
    "        \n",
    "#         print(node, out_neighbors)\n",
    "        \n",
    "#         G.add_edges_from(map(lambda d:(node, d), out_neighbors))\n",
    "        \n",
    "        for out_neighbor in out_neighbors:\n",
    "            G.add_edge(node, out_neighbor, weight=random.uniform(weight_min, weight_max))\n",
    "        \n",
    "    return G\n",
    "\n",
    "def generate_rand_weighted_g(node_size=NUM_NODE, p=0.02, directed=True, weight_min=WEIGHT_MIN, weight_max=WEIGHT_MAX):\n",
    "\n",
    "    rnd_g = nx.erdos_renyi_graph(node_size, p, directed=directed)\n",
    "\n",
    "    for edge in rnd_g.edges(data=True):\n",
    "        rnd_g.add_edge(edge[0], edge[1], weight=random.uniform(weight_min, weight_max))\n",
    "        \n",
    "    return rnd_g\n",
    "\n",
    "def print_g(G):\n",
    "    for edge in G.edges(data=True):\n",
    "        print(edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "G = generate_low_degree_g()\n",
    "print(G.number_of_nodes())\n",
    "print(G.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(G, with_labels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_out_degree = max(G.out_degree, key=lambda d: d[1])[1]\n",
    "max_out_degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(idx, length=max_out_degree):\n",
    "    \n",
    "    ret = np.zeros(length)\n",
    "    ret[idx] = 1.0\n",
    "    return ret\n",
    "\n",
    "def generate_dataset(G):\n",
    "    \n",
    "    X, y = [], []\n",
    "    \n",
    "    for node in G.nodes:\n",
    "\n",
    "        if G.out_degree(node) == 0:\n",
    "            print('Node %d has 0 out degree' % node)\n",
    "            continue\n",
    "\n",
    "        init_weight_vec = np.ones(max_out_degree)\n",
    "\n",
    "        for idx, out_edge in enumerate(G.out_edges(node)):\n",
    "            init_weight_vec[idx] = G.get_edge_data(node, out_edge[1])['weight']\n",
    "\n",
    "        out_neighbors = map(lambda t: (t[1], G.get_edge_data(node, t[1])['weight']),  G.out_edges(node))\n",
    "    #     print(node, min(out_neighbors, key=lambda d: d[1]), len(out_neighbors), sorted(out_neighbors))\n",
    "\n",
    "    #     label = one_hot_encode(np.argmin(init_weight_vec, axis=0))\n",
    "        label = min(out_neighbors, key=lambda d: d[1])[1]\n",
    "    #     print(label, init_weight_vec[np.argmin(init_weight_vec)])\n",
    "        assert label == init_weight_vec[np.argmin(init_weight_vec)]\n",
    "        X.append(init_weight_vec)\n",
    "        y.append(label)\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "features, labels = generate_dataset(G)\n",
    "print(features.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_dataset(X, y=None, augmentation_index=10):\n",
    "    \n",
    "    X_aug, y_aug = [], []\n",
    "    indices = np.arange(len(X[0]))\n",
    "    \n",
    "    for idx, x in enumerate(X):\n",
    "        for _ in range(augmentation_index):\n",
    "            np.random.shuffle(indices)\n",
    "            \n",
    "            X_aug.append(x[indices])\n",
    "            y_aug.append(one_hot_encode(np.argmin(x[indices])))\n",
    "            \n",
    "    return np.array(X_aug), np.array(y_aug)\n",
    "\n",
    "def augment_dataset_extend_features(X, y=None, augmentation_index=10):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_aug, y_aug = augment_dataset(features, labels, augmentation_index=300)\n",
    "print(X_aug.shape)\n",
    "print(y_aug.shape)\n",
    "print(X_aug[0])\n",
    "print(y_aug[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(X_aug))\n",
    "np.random.shuffle(indices)\n",
    "X, y =  X_aug[indices], y_aug[indices]\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.9, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "train_iter = mx.io.NDArrayIter(X_train, y_train, batch_size, shuffle=True)\n",
    "val_iter = mx.io.NDArrayIter(X_test, y_test, batch_size=len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(context=mx.gpu()):\n",
    "    \n",
    "    data = mx.sym.var('data')\n",
    "    label = mx.sym.var('softmax_label')\n",
    "    \n",
    "    fc2  = mx.sym.FullyConnected(data=data, num_hidden=32)\n",
    "    fc2 = mx.sym.Activation(data=fc2, act_type=\"relu\")\n",
    "    \n",
    "    fc3  = mx.sym.FullyConnected(data=fc2, num_hidden=max_out_degree)\n",
    "    mlp  = mx.sym.SoftmaxOutput(data=fc3, label=label)\n",
    "    \n",
    "    return mx.mod.Module(symbol=mlp, context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger().setLevel(logging.DEBUG)  # logging to stdout\n",
    "model = build_model()\n",
    "model.bind(data_shapes=train_iter.provide_data, label_shapes=train_iter.provide_label)\n",
    "model.init_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_acc(label, pred):\n",
    "    tmp_label = np.argmax(label, axis=1)\n",
    "    tmp_pred = np.argmax(pred, axis=1)\n",
    "    return accuracy_score(tmp_label, tmp_pred)\n",
    "\n",
    "custom_metric = mx.metric.create(custom_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_iter,  # train data\n",
    "              eval_data=val_iter,  # validation data\n",
    "              optimizer='adam',  # use SGD to train\n",
    "#               optimizer_params={'learning_rate':0.01, 'momentum': 0.9},\n",
    "              eval_metric=custom_metric,  # report accuracy during training\n",
    "              batch_end_callback = mx.callback.Speedometer(batch_size, 10), # output progress for each 100 data batches\n",
    "              num_epoch=20)  # train for at most 10 dataset passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = np.argmax(model.predict(mx.io.NDArrayIter(X_train, y_train, batch_size=len(y_train))).asnumpy(), axis=1)\n",
    "print('Acc on training set %f' % accuracy_score(np.argmax(y_train, axis=1), pred_train))\n",
    "\n",
    "pred_test = np.argmax(model.predict(mx.io.NDArrayIter(X_test, y_test, batch_size=len(y_test))).asnumpy(), axis=1)\n",
    "print('Acc on test set %f' % accuracy_score(np.argmax(y_test, axis=1), pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_next_node(G, cur_node):\n",
    "#     print(\"In infer_next_node\")\n",
    "    return min(map(lambda t: (t[1], G.get_edge_data(cur_node, t[1])['weight']),  G.out_edges(cur_node)), key=lambda d:d[1])\n",
    "\n",
    "def nn_infer_next_node(G, cur_node, model):\n",
    "#     print(\"In nn_infer_next_node\")\n",
    "    input_vec = np.ones(4)\n",
    "    \n",
    "    for idx, out_edge in enumerate(G.out_edges(cur_node)):\n",
    "        input_vec[idx] = G.get_edge_data(cur_node, out_edge[1])['weight']\n",
    "    \n",
    "    \n",
    "    out_neighbors = map(lambda t: (t[1], G.get_edge_data(cur_node, t[1])['weight']),  G.out_edges(cur_node))\n",
    "    \n",
    "    pred_idx = np.argmax(model.predict(mx.io.NDArrayIter(np.array([input_vec]), np.array([0]))).asnumpy()[0])\n",
    "    return out_neighbors[pred_idx]\n",
    "\n",
    "def greedy_path_finder(G, src, dst, use_nn=False, model=None):\n",
    "    \n",
    "    path = [src]\n",
    "    cur_node = src\n",
    "    total_weights = .0\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        if len(path) >= G.number_of_nodes():\n",
    "            return path, total_weights, False\n",
    "        \n",
    "        next_node, weight = nn_infer_next_node(G, cur_node, model) if use_nn else infer_next_node(G, cur_node)\n",
    "        total_weights += weight\n",
    "        path.append(next_node)\n",
    "        \n",
    "        if next_node == dst:\n",
    "            return path, total_weights, True\n",
    "        \n",
    "        cur_node = next_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src, dst = 9, 2\n",
    "\n",
    "print greedy_path_finder(G, src, dst)\n",
    "print greedy_path_finder(G, src, dst, use_nn=True, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.dijkstra_path(G, src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_greedy_path_finder_acc(G, model):\n",
    "    \n",
    "    correct_cnt = 0\n",
    "    \n",
    "    for src in G.nodes:\n",
    "        for dst in G.nodes:\n",
    "            \n",
    "            if src == dst:\n",
    "                continue\n",
    "            \n",
    "            path, _, found = greedy_path_finder(G, src, dst)\n",
    "            nn_path, _, nn_found = greedy_path_finder(G, src, dst, use_nn=True, model=model)\n",
    "            \n",
    "            if found == nn_found and path == nn_path:\n",
    "                correct_cnt = correct_cnt + 1\n",
    "            else:\n",
    "                print('src %d dst %d incorrect' % (src, dst))\n",
    "    \n",
    "    num_nodes = G.number_of_nodes()\n",
    "    return float(correct_cnt) / (num_nodes*(num_nodes-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_1 = generate_low_degree_g()\n",
    "print(G_1.number_of_nodes())\n",
    "print(G_1.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_greedy_path_finder_acc(G_1, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nx.single_source_dijkstra_path(G_1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_dijkstra(G, src):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = Queue.PriorityQueue()\n",
    "q.put((10,'ten'))\n",
    "q.put((1,'one'))\n",
    "q.put((5,'five'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q.qsize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
