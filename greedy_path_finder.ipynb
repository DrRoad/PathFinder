{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Some take-ways from this notebook\n",
    "\n",
    "Greedy strategy can be perfectly and easily approximated by a neural network;\n",
    "However, greedy strategy itself is sub-optimal compared to shortest path strategies; the \n",
    "algorithm can easily be stuck in a cycle, leading to bad results.\n",
    "\n",
    "One thing that is a bit concerning is that the graph is small; the network\n",
    "tends to memorize the entire graph; some experiments on much bigger graphs\n",
    "should be conducted to verify that the network is actually learning something\n",
    "useful.\n",
    "\n",
    "It would be very interesting to see to what extent shortest path strategy can be approximated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "import logging\n",
    "from sklearn.metrics import accuracy_score\n",
    "from utils import generate_low_degree_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "G = generate_low_degree_g(num_nodes=100)\n",
    "print(G.number_of_nodes())\n",
    "print(G.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "nx.draw(G, with_labels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "max_out_degree = max(G.out_degree, key=lambda d: d[1])[1]\n",
    "max_out_degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def generate_dataset(G):\n",
    "    \n",
    "    X, y = [], []\n",
    "    \n",
    "    for node in G.nodes:\n",
    "\n",
    "        if G.out_degree(node) == 0:\n",
    "            print('Node %d has 0 out degree' % node)\n",
    "            continue\n",
    "\n",
    "        init_weight_vec = np.ones(max_out_degree)\n",
    "\n",
    "        for idx, out_edge in enumerate(G.out_edges(node)):\n",
    "            init_weight_vec[idx] = G.get_edge_data(node, out_edge[1])['weight']\n",
    "\n",
    "        out_neighbors = map(lambda t: (t[1], G.get_edge_data(node, t[1])['weight']),  G.out_edges(node))\n",
    "    #     print(node, min(out_neighbors, key=lambda d: d[1]), len(out_neighbors), sorted(out_neighbors))\n",
    "\n",
    "    #     label = one_hot_encode(np.argmin(init_weight_vec, axis=0))\n",
    "        label = min(out_neighbors, key=lambda d: d[1])[1]\n",
    "    #     print(label, init_weight_vec[np.argmin(init_weight_vec)])\n",
    "        assert label == init_weight_vec[np.argmin(init_weight_vec)]\n",
    "        X.append(init_weight_vec)\n",
    "        y.append(label)\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "features, labels = generate_dataset(G)\n",
    "print(features.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def augment_dataset(X, y=None, augmentation_index=600):\n",
    "    \n",
    "    X_aug, y_aug = [], []\n",
    "    indices = np.arange(len(X[0]))\n",
    "    \n",
    "    for _, x in enumerate(X):\n",
    "        for _ in range(augmentation_index):\n",
    "#             np.random.shuffle(indices)\n",
    "            \n",
    "            X_aug.append(x[indices])\n",
    "            y_aug.append(np.argmin(x[indices]))\n",
    "            \n",
    "    return np.array(X_aug), np.array(y_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_aug, y_aug = augment_dataset(features, labels, augmentation_index=1)\n",
    "print(X_aug.shape)\n",
    "print(y_aug.shape)\n",
    "print(X_aug[1])\n",
    "print(y_aug[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "indices = np.arange(len(X_aug))\n",
    "np.random.shuffle(indices)\n",
    "X, y =  X_aug[indices], y_aug[indices]\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "\n",
    "train_iter = mx.io.NDArrayIter(X, y, batch_size, shuffle=True)\n",
    "val_iter = mx.io.NDArrayIter(X, y, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_model(context=mx.cpu()):\n",
    "    \n",
    "    data = mx.sym.var('data')\n",
    "    label = mx.sym.var('softmax_label')\n",
    "    \n",
    "    fc2  = mx.sym.FullyConnected(data=data, num_hidden=32)\n",
    "    fc2 = mx.sym.Activation(data=fc2, act_type=\"relu\")\n",
    "    \n",
    "    fc3  = mx.sym.FullyConnected(data=fc2, num_hidden=max_out_degree)\n",
    "    mlp  = mx.sym.SoftmaxOutput(data=fc3, label=label)\n",
    "    \n",
    "    return mx.mod.Module(symbol=mlp, context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "logging.getLogger().setLevel(logging.DEBUG)  # logging to stdout\n",
    "model = build_model()\n",
    "model.bind(data_shapes=train_iter.provide_data, label_shapes=train_iter.provide_label)\n",
    "model.init_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(train_iter,  # train data\n",
    "              eval_data=val_iter,  # validation data\n",
    "              optimizer='adam',  # use SGD to train\n",
    "#               optimizer_params={'learning_rate':0.01, 'momentum': 0.9},\n",
    "              eval_metric='acc',  # report accuracy during training\n",
    "              batch_end_callback = mx.callback.Speedometer(batch_size, 10), # output progress for each 100 data batches\n",
    "              num_epoch=10)  # train for at most 10 dataset passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pred_train = np.argmax(model.predict(mx.io.NDArrayIter(X_train, y_train, batch_size=batch_size)).asnumpy(), axis=1)\n",
    "print('Acc on training set %f' % accuracy_score(y_train, pred_train))\n",
    "\n",
    "pred_test = np.argmax(model.predict(mx.io.NDArrayIter(X_test, y_test, batch_size=batch_size)).asnumpy(), axis=1)\n",
    "print('Acc on test set %f' % accuracy_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def infer_next_node(G, cur_node):\n",
    "#     print(\"In infer_next_node\")\n",
    "    return min(map(lambda t: (t[1], G.get_edge_data(cur_node, t[1])['weight']),  G.out_edges(cur_node)), key=lambda d:d[1])\n",
    "\n",
    "def nn_infer_next_node(G, cur_node, model):\n",
    "#     print(\"In nn_infer_next_node\")\n",
    "    input_vec = np.ones(4)\n",
    "    \n",
    "    for idx, out_edge in enumerate(G.out_edges(cur_node)):\n",
    "        input_vec[idx] = G.get_edge_data(cur_node, out_edge[1])['weight']\n",
    "    \n",
    "    \n",
    "    out_neighbors = map(lambda t: (t[1], G.get_edge_data(cur_node, t[1])['weight']),  G.out_edges(cur_node))\n",
    "    \n",
    "    pred_idx = np.argmax(model.predict(mx.io.NDArrayIter(np.array([input_vec]), np.array([0]))).asnumpy()[0])\n",
    "    return out_neighbors[pred_idx]\n",
    "\n",
    "def greedy_path_finder(G, src, dst, use_nn=False, model=None):\n",
    "    \n",
    "    path = [src]\n",
    "    cur_node = src\n",
    "    total_weights = .0\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        if len(path) >= G.number_of_nodes():\n",
    "            return path, total_weights, False\n",
    "        \n",
    "        next_node, weight = nn_infer_next_node(G, cur_node, model) if use_nn else infer_next_node(G, cur_node)\n",
    "        total_weights += weight\n",
    "        path.append(next_node)\n",
    "        \n",
    "        if next_node == dst:\n",
    "            return path, total_weights, True\n",
    "        \n",
    "        cur_node = next_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def check_greedy_path_finder_acc(G, model):\n",
    "    \n",
    "    identical_cnt = 0\n",
    "    other_cnt = 0\n",
    "    \n",
    "    for src in G.nodes:\n",
    "        for dst in G.nodes:\n",
    "            \n",
    "            if src == dst:\n",
    "                continue\n",
    "            \n",
    "            path, _, found = greedy_path_finder(G, src, dst)\n",
    "            nn_path, _, nn_found = greedy_path_finder(G, src, dst, use_nn=True, model=model)\n",
    "            \n",
    "            if path == nn_path:\n",
    "                identical_cnt += 1\n",
    "            else:\n",
    "                other_cnt += 1\n",
    "            \n",
    "#             if found == nn_found and found == True:\n",
    "#                 basic_stat[0] += 1\n",
    "                \n",
    "#                 if path == nn_path:\n",
    "#                     extra_stat['eq'] += 1\n",
    "#                 elif len(path) < len(nn_path):\n",
    "#                     extra_stat['nn_path_more'] += 1\n",
    "#                 elif len(path) > len(nn_path):\n",
    "#                     extra_stat['path_more'] += 1\n",
    "#                 else:\n",
    "#                     pass\n",
    "# #                     assert False\n",
    "# #                     print 'greedy_path_finder', path\n",
    "# #                     print 'nn_greedy_path_finder', nn_path\n",
    "                \n",
    "#             elif found == nn_found and found == False:\n",
    "#                 basic_stat[1] += 1\n",
    "#             elif found == True and nn_found == False:\n",
    "#                 basic_stat[2] += 1\n",
    "#             elif found == False and nn_found == True:\n",
    "# #                 print src, dst\n",
    "# #                 print 'greedy_path_finder', path\n",
    "# #                 print 'nn_greedy_path_finder', nn_path\n",
    "#                 basic_stat[3] += 1\n",
    "#             else:\n",
    "#                 assert False\n",
    "    \n",
    "    return identical_cnt, other_cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate on new graphs\n",
    "\n",
    "A model that is trained on one random graph\n",
    "should and indeed can be used to infer paths\n",
    "on another random graph. This, to some extent,\n",
    "proves that the network has gained some knowledge,\n",
    "which is good news.\n",
    "In this case, the knowledge is the greedy strategy,\n",
    "i.e., always go with the edge that has the smallest\n",
    "weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph_sizes = [20, 100, 500, 1000]\n",
    "stats = [[] for _ in range(len(graph_sizes))]\n",
    "number_of_tests = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx, num_nodes in enumerate(graph_sizes):\n",
    "    \n",
    "    print('Working on graphs with %d nodes' % num_nodes)\n",
    "    for i in range(number_of_tests):\n",
    "        \n",
    "        if i > 0 and i % 10 == 0:\n",
    "            print(\"Processed %d graphs\" % i)\n",
    "            \n",
    "        G_1 = generate_low_degree_g(num_nodes=num_nodes)\n",
    "        X_test, y_test = generate_dataset(G_1)\n",
    "        X_test, y_test = augment_dataset(X_test, y_test, augmentation_index=1)\n",
    "\n",
    "        pred_test = np.argmax(model.predict(mx.io.NDArrayIter(X_test, y_test)).asnumpy(), axis=1)\n",
    "        acc = accuracy_score(y_test, pred_test)\n",
    "        stats[idx].append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for idx, stat in enumerate(stats):\n",
    "    stat_mean = np.mean(stat)\n",
    "    stat_std = np.std(stat)\n",
    "    label = u'%d nodes, μ=%f, σ=%f' % \\\n",
    "            (graph_sizes[idx], stat_mean, stat_std)\n",
    "    plt.scatter(list(range(number_of_tests)), stat, label=label)\n",
    "    \n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
